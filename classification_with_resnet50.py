# -*- coding: utf-8 -*-
"""Question1 with ResNet50 DAI_Assignment2_1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1_eLXNuRFzCDqsQHBLrwFs_H6WHKBE0SX
"""

from google.colab import drive
drive.mount('/content/drive')

!unzip /content/drive/MyDrive/D_10_Dataset.zip

!pip install git+https://github.com/cleverhans-lab/cleverhans/

pip install adversarial-robustness-toolbox

import keras,os
from keras.models import Sequential
from keras.layers import Dense, Conv2D, MaxPool2D , Flatten
from keras.preprocessing.image import ImageDataGenerator
import matplotlib.pyplot as plt
import numpy as np
import cv2 
import tensorflow as tf
from sklearn import model_selection, svm, preprocessing
from keras.applications.vgg16 import VGG16
from keras.applications.resnet50 import ResNet50
from keras.callbacks import ModelCheckpoint, EarlyStopping
from keras.utils import to_categorical
from skimage.measure import compare_ssim
import pandas as pd
from sklearn.metrics import classification_report
from cleverhans.future.tf2.attacks import fast_gradient_method, \
    basic_iterative_method, momentum_iterative_method
#from cleverhans.attacks.ca
import pickle
import PIL
import math
from art.attacks.evasion import CarliniLInfMethod
from art.estimators.classification import TensorFlowV2Classifier
from sewar.full_ref import uqi,psnr,scc

"""# Data Intialization"""

trdata = ImageDataGenerator(rescale=1/255,
    validation_split=0.2)
traindata = trdata.flow_from_directory(directory="/content/Images",target_size=(32,32), subset='training',batch_size=20947)
testdata = trdata.flow_from_directory(directory="/content/Images",target_size=(32,32), subset='validation',batch_size=5232)

with open('/content/drive/MyDrive/res50_shubh_daiASS2/res50_train_32.pickle', 'rb') as f:
    x_train_n, y_train_n = pickle.load(f)

with open('/content/drive/MyDrive/res50_shubh_daiASS2/res50_test_32.pickle', 'rb') as f:
    x_test_n, y_test_n = pickle.load(f)

with open('/content/drive/MyDrive/res50_shubh_daiASS2/res50_x_test_adv_ntar_32.pickle', 'rb') as f:
    x_test_pert_n = pickle.load(f)

"""# Tarining on Original Samples"""

model = ResNet50(include_top=True, weights="/content/drive/MyDrive/res50_shubh_daiASS2/res50_weight_img32_23012021.h5", input_tensor=None,
    input_shape=(32,32,3),classes=10)

model.compile(optimizer="rmsprop", loss=keras.losses.categorical_crossentropy, metrics=['accuracy'])

# checkpoint = ModelCheckpoint("/content/drive/MyDrive/vgg16_1_14_2021_1.h5", monitor='val_accuracy', verbose=1, save_best_only=True, save_weights_only=False, mode='auto')
# early = EarlyStopping(monitor='val_accuracy', min_delta=0, patience=5, verbose=1, mode='auto')

# hist = model.fit(traindata, validation_data= testdata, validation_steps=10,epochs=100,callbacks=[checkpoint,early])

score = model.evaluate(testdata)

model_hist = pd.read_csv('/content/drive/MyDrive/res50_shubh_daiASS2/res50_32_23012021_history.csv')

# model_hist['val_loss'][0] = 3.124159
# model_hist['val_loss'][2] = 5.726342
# model_hist['val_loss'][4] = 5.363422
# model_hist['val_loss'][13] = 2.738354
# model_hist['val_loss'][16] = 1.925131

model_hist

epochs = range(0,19)
plt.plot(epochs,list(model_hist['val_loss']), 'g', label='Testing loss')
plt.plot(epochs,list(model_hist['loss']), 'b', label='Training loss')
plt.title('Training and Testing loss with Resnet50')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.show()

image_prob = model.predict(testdata)
pred_test_labels_new = np.argmax(image_prob,axis=1)

pred_test_labels = to_categorical(pred_test_labels_new, dtype='float16',num_classes=10)

print(f"Classification report for Resnet50:\n"
      f"{classification_report(pred_test_labels,testdata[0][1])}\n")

"""# Attacks"""

labels = ['cane','cavallo','elefante','farfalla','gallina','gatto','mucca','pecora','ragno','scoiattolo']
img_rows, img_cols, channels = 32, 32, 3

logits_model = tf.keras.Model(model.input, model.layers[-1].output)

original_image = testdata[0][0][1110]#10
original_image_label = testdata[0][1][1110]
original_image = tf.convert_to_tensor(original_image.reshape((1,32,32,3))) #The .reshape just gives it the proper form to input into the model, a batch of 1 a.k.a a tensor

"""## 1) FGSM"""

epsilon = 0.1

adv_example_untargeted_label = fast_gradient_method(logits_model, original_image, epsilon, np.inf, targeted=False)
adv_example_untargeted_label_pred = model.predict(adv_example_untargeted_label)
original_image_label_pred = model.predict(original_image)

plt.figure(figsize=(13,4))
plt.subplot(1,2,1)
plt.title("Model Prediction: {}".format(labels[np.argmax(original_image_label_pred)]))
plt.imshow(original_image[0])
plt.xlabel("Original Label: {}".format(labels[np.where(original_image_label == 1)[0][0]]))
plt.subplot(1,2,2)
plt.imshow(adv_example_untargeted_label[0])
plt.title("Model Prediction: {}".format(labels[np.argmax(adv_example_untargeted_label_pred)]))
plt.xlabel("Original Label: {}".format(labels[np.where(original_image_label == 1)[0][0]]))
plt.show()

(score, diff) = compare_ssim(np.array(original_image[0]), np.array(adv_example_untargeted_label[0]), full=True, multichannel=True)
diff = (diff * 255).astype("uint8")
print("SSIM: {}".format(score))

epsilon = 0.2
# The target value may have to be changed to work, some images are more easily missclassified as different labels
target = 0 #cane

target_label = np.reshape(target, (1,)).astype('int64') # Give target label proper size and dtype to feed through

adv_example_targeted_label = fast_gradient_method(logits_model, original_image, epsilon, np.inf, y=target_label, targeted=True)

adv_example_targeted_label_pred = model.predict(adv_example_targeted_label)

plt.figure(figsize=(13,4))
plt.subplot(1,2,1)
plt.title("Model Prediction: {}".format(labels[np.argmax(original_image_label_pred)]))
plt.imshow(original_image[0])
plt.xlabel("Original Label: {}".format(labels[np.where(original_image_label == 1)[0][0]]))
plt.subplot(1,2,2)
plt.imshow(np.reshape(adv_example_targeted_label, (32,32,3)))
plt.title("Model Prediction: {}".format(labels[np.argmax(adv_example_targeted_label_pred)]))
plt.xlabel("Original Label: {}".format(labels[np.where(original_image_label == 1)[0][0]]))
plt.show()

(score, diff) = compare_ssim(np.array(original_image[0]), np.array(adv_example_targeted_label[0]), full=True, multichannel=True)
diff = (diff * 255).astype("uint8")
print("SSIM: {}".format(score))

"""## 2) BIM"""

epsilon = 0.2
adv_example_untargeted_label = basic_iterative_method(logits_model,
                                       original_image,
                                       epsilon,
                                       0.1,
                                       nb_iter=10,
                                       norm=np.inf,
                                       targeted=False)
adv_example_untargeted_label_pred = model.predict(adv_example_untargeted_label)

plt.figure(figsize=(13,4))
plt.subplot(1,2,1)
plt.title("Model Prediction: {}".format(labels[np.argmax(original_image_label_pred)]))
plt.imshow(original_image[0])
plt.xlabel("Original Label: {}".format(labels[np.where(original_image_label == 1)[0][0]]))
plt.subplot(1,2,2)
plt.imshow(np.reshape(adv_example_untargeted_label, (32,32,3)))
plt.title("Model Prediction: {}".format(labels[np.argmax(adv_example_untargeted_label_pred)]))
plt.xlabel("Original Label: {}".format(labels[np.where(original_image_label == 1)[0][0]]))
plt.show()

(score, diff) = compare_ssim(np.array(original_image[0]), np.array(adv_example_untargeted_label[0]), full=True, multichannel=True)
diff = (diff * 255).astype("uint8")
print("SSIM: {}".format(score))

epsilon = .3
target = 8

target_label = np.reshape(target, (1,)).astype('int64') # Give target label proper size and dtype to feed through


adv_example_targeted_label = basic_iterative_method(logits_model,
                                       original_image,
                                       epsilon,
                                       0.1,
                                       nb_iter=10,
                                       norm=np.inf,
                                       targeted=True,
                                       y=target_label)
adv_example_targeted_label_pred = model.predict(adv_example_untargeted_label)

plt.figure(figsize=(13,4))
plt.subplot(1,2,1)
plt.title("Model Prediction: {}".format(labels[np.argmax(original_image_label_pred)]))
plt.imshow(original_image[0])
plt.xlabel("Original Label: {}".format(labels[np.where(original_image_label == 1)[0][0]]))
plt.subplot(1,2,2)
plt.imshow(np.reshape(adv_example_targeted_label, (32,32,3)))
plt.title("Model Prediction: {}".format(labels[np.argmax(adv_example_targeted_label_pred)]))
plt.xlabel("Original Label: {}".format(labels[np.where(original_image_label == 1)[0][0]]))
plt.show()

(score, diff) = compare_ssim(np.array(original_image[0]), np.array(adv_example_targeted_label[0]), full=True, multichannel=True)
diff = (diff * 255).astype("uint8")
print("SSIM: {}".format(score))

"""## 3) C&W"""

classifier = TensorFlowV2Classifier(model=model, nb_classes=10, input_shape=(32, 32, 3), 
                                    clip_values=(0, 1), channels_first=False, loss_object = tf.keras.losses.SparseCategoricalCrossentropy())

epsilon = 0.4

cnw_attack = CarliniLInfMethod(classifier=classifier, eps=epsilon, max_iter=10, learning_rate=0.2,targeted=False)

adv_example_untargeted_label = cnw_attack.generate(original_image)
adv_example_untargeted_label_pred = model.predict(adv_example_untargeted_label)

plt.figure(figsize=(13,4))
plt.subplot(1,2,1)
plt.title("Model Prediction: {}".format(labels[np.argmax(original_image_label_pred)]))
plt.imshow(original_image[0])
plt.xlabel("Original Label: {}".format(labels[np.where(original_image_label == 1)[0][0]]))
plt.subplot(1,2,2)
plt.imshow(np.reshape(adv_example_untargeted_label, (32,32,3)))
plt.title("Model Prediction: {}".format(labels[np.argmax(adv_example_untargeted_label_pred)]))
plt.xlabel("Original Label: {}".format(labels[np.where(original_image_label == 1)[0][0]]))
plt.show()

(score, diff) = compare_ssim(np.array(original_image[0]), np.array(adv_example_untargeted_label[0]), full=True, multichannel=True)
diff = (diff * 255).astype("uint8")
print("SSIM: {}".format(score))

epsilon = 0.3
target = 0

target_label = np.reshape(target, (1,)).astype('int64') # Give target label proper size and dtype to feed through


cnw_attack = CarliniLInfMethod(classifier=classifier, eps=epsilon, max_iter=10, learning_rate=0.2,targeted=True)

adv_example_targeted_label = cnw_attack.generate(original_image,target_label)
adv_example_targeted_label_pred = model.predict(adv_example_untargeted_label)

plt.figure(figsize=(13,4))
plt.subplot(1,2,1)
plt.title("Model Prediction: {}".format(labels[np.argmax(original_image_label_pred)]))
plt.imshow(original_image[0])
plt.xlabel("Original Label: {}".format(labels[np.where(original_image_label == 1)[0][0]]))
plt.subplot(1,2,2)
plt.imshow(np.reshape(adv_example_targeted_label, (32,32,3)))
plt.title("Model Prediction: {}".format(labels[np.argmax(adv_example_targeted_label_pred)]))
plt.xlabel("Original Label: {}".format(labels[np.where(original_image_label == 1)[0][0]]))
plt.show()

(score, diff) = compare_ssim(np.array(original_image[0]), np.array(adv_example_targeted_label[0]), full=True, multichannel=True)
diff = (diff * 255).astype("uint8")
print("SSIM: {}".format(score))

"""# Detection: Adversarial Perturbation Metrics"""

def psnr(img1, img2):
    mse = np.mean( (img1 - img2) ** 2 )
    if mse == 0:
      return 100
    PIXEL_MAX = 255.0
    return 20 * math.log10(PIXEL_MAX / math.sqrt(mse))

d=psnr(original_image,np.reshape(adv_example_untargeted_label, (32,32,3)))
print("psnr score between original and adversarial image: ",d)

uqi_score = uqi(original_image[0].numpy(),np.reshape(adv_example_untargeted_label, (32,32,3)))
print("uqi score between original and adversarial image: ",uqi_score)

"""# Training on Perturbed Samples"""

model_1 = ResNet50(include_top=True, weights="/content/drive/MyDrive/res50_shubh_daiASS2/res50_weight_pertimg32_24012021.h5", input_tensor=None,
    input_shape=(32,32,3),classes=10)

model_1.compile(optimizer="rmsprop", loss=keras.losses.categorical_crossentropy, metrics=['accuracy'])

epsilon = 0.1

adv_example_untargeted_label_test = fast_gradient_method(logits_model, testdata[0][0], epsilon, np.inf, targeted=False)
#adv_example_untargeted_label_train = fast_gradient_method(logits_model, traindata[0][0], epsilon, np.inf, targeted=False)

model_1.evaluate(x_test_pert_n,y_test_n)

model_1_hist = pd.read_csv('/content/drive/MyDrive/res50_shubh_daiASS2/res50_pertimg32_24012021_history.csv')

model_1_hist

epochs = range(0,26)
plt.plot(epochs,list(model_1_hist['val_loss']), 'g', label='Testing loss')
plt.plot(epochs,list(model_1_hist['loss']), 'b', label='Training loss')
plt.title('Training and Testing loss with Resnet50')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.show()

image_prob = model_1.predict(x_test_pert_n)
pred_test_labels_new = np.argmax(image_prob,axis=1)

pred_test_labels = to_categorical(pred_test_labels_new, dtype='float16',num_classes=10)

print(f"Classification report for Resnet50 on perturbed training:\n"
      f"{classification_report(pred_test_labels,y_test_n)}\n")

model.evaluate(x_test_pert_n,y_test_n)

"""## Mitigation: JPEG Compression"""

def jpeg_compress(x, quality):
    img = np.reshape(x, (32,32,3)) * 255
    return tf.image.decode_jpeg(
        tf.image.encode_jpeg(
            img, format='rgb', quality=quality),
        channels=3)

test_compr_img = []
for i in x_test_pert_n :
  test_compr_img.append(jpeg_compress(i,25))

test_compr_img = np.array(test_compr_img) / 255

model.evaluate(test_compr_img,y_test_n)

image_prob = model.predict(test_compr_img)
pred_test_labels_new = np.argmax(image_prob,axis=1)

pred_test_labels = to_categorical(pred_test_labels_new, dtype='float16',num_classes=10)

print(f"Classification report for Resnet50 on compression rate 25%:\n"
      f"{classification_report(pred_test_labels,y_test_n)}\n")

test_compr_img = []
for i in x_test_pert_n :
  test_compr_img.append(jpeg_compress(i,50))

test_compr_img = np.array(test_compr_img) / 255

model.evaluate(test_compr_img,y_test_n)

image_prob = model.predict(test_compr_img)
pred_test_labels_new = np.argmax(image_prob,axis=1)

pred_test_labels = to_categorical(pred_test_labels_new, dtype='float16',num_classes=10)

print(f"Classification report for Resnet50 on compression rate 50%:\n"
      f"{classification_report(pred_test_labels,y_test_n)}\n")

